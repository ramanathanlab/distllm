# AGPT 1.5B Base Configuration with Checkpointing and Progress Monitoring
# Strategy: Single vLLM server optimized for smaller model + comprehensive checkpointing

questions_file: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/HR-GOOD-10-MC.json"

model:
  generator:
    generator_type: "vllm"
  
  generator_settings:
    # Traditional fields
    server: "localhost"
    port: 8000
    api_key: "CELS"
    model: "agpt1p5b-base"  # Update with actual model name/path
    temperature: 0.0
    max_tokens: 1024
    
    # Local vLLM server configuration
    boot_local: true
    hf_model_id: "/rbstor/ac.ogokdemir/ArgoniumRick/agpt-checkpoints/lucid_papers/ckpt_agpt_1.5B_base/HF/ws48_ds_stage1_nl24_hs2048_mb1_seq2048_gb3072_sp1_pp1_tp1_bf16_optipex.fusedlamb_lr0.000761_lwf/global_step7947_hf"  # Update with actual HuggingFace model ID or local path
    auto_port: true
    local_host: "127.0.0.1"
    server_startup_timeout: 600
    
    # vLLM arguments optimized for 1.5B model (single GPU should suffice)
    vllm_args:
      tensor_parallel_size: 2  # Single GPU for 1.5B model
      max_model_len: 2048      # Conservative context length for base model
      gpu_memory_utilization: 0.8  # Lower utilization for smaller model
      dtype: "auto"
      trust_remote_code: true
      seed: 42
      pipeline_parallel_size: 1
      max_num_batched_tokens: 8192   # Smaller than 8B model
      max_num_seqs: 128              # Reduced for smaller model
      
    # Request batching configuration
    enable_batching: true
    batch_size: 16    # Smaller batch size for 1.5B model
    batch_timeout: 1.0
  
  grader_shortname: "gpt-4.1"
  model_config_file: "model_servers.yaml"

rag:
  enabled: false  # Disable for pure generation testing
  use_context_field: false

processing:
  parallel_workers: 4  # Fewer workers for smaller model
  question_format: "mc"
  verbose: true
  random_selection: null
  random_seed: 42
  
  # âœ¨ NEW: Comprehensive Checkpointing and Progress Monitoring
  enable_checkpointing: true              # Enable automatic checkpointing
  checkpoint_interval: 100                # Save checkpoint every 100 completed questions
  checkpoint_directory: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/agpt1p5b-base/checkpoints/"     # Directory for checkpoint files
  resume_from_checkpoint: null            # Specify checkpoint file to resume from (null = auto-detect)
  auto_resume: true                       # Automatically resume from latest checkpoint
  progress_bar: true                      # Show progress bar with percentage
  save_incremental: false                 # Ultra-safe mode: save after every question (slower)

output:
  save_incorrect: true
  output_directory: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/agpt1p5b-base"
  output_prefix: "agpt1p5b-base_norag"

# ðŸ”‹ Production Safety Features:
# - Automatic checkpointing every 100 questions
# - Auto-resume from crashes/interruptions  
# - Progress monitoring with percentage completion
# - Memory-safe: doesn't store everything in RAM
# - Crash recovery: can resume from any checkpoint
# - Ultra-safe mode option for critical workloads
# - Optimized for 1.5B parameter model (single GPU, smaller batches)
