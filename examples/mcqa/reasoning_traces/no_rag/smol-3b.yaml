# Enhanced Mistral-7B Configuration with Checkpointing and Progress Monitoring
# Strategy: Single vLLM server with tensor parallelism + batching + comprehensive checkpointing

questions_file: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/HR-GOOD-10-MC.json"

model:
  generator:
    generator_type: "vllm"
  
  generator_settings:
    # Traditional fields
    server: "localhost"
    port: 8000
    api_key: "CELS"
    model: "HuggingFaceTB/SmolLM3-3B"
    temperature: 0.0
    max_tokens: 64
    
    # Local vLLM server configuration
    boot_local: true
    hf_model_id: "HuggingFaceTB/SmolLM3-3B"
    auto_port: true
    local_host: "127.0.0.1"
    server_startup_timeout: 600
    
    # vLLM arguments for 8-GPU tensor parallelism
    vllm_args:
      tensor_parallel_size: 1
      max_model_len: 4096
      gpu_memory_utilization: 0.95
      dtype: "auto"
      trust_remote_code: false
      seed: 42
      
      # Chat template for SmolLM3-3B (supports system + user message format)
      chat_template: "{% for message in messages %}{% if message['role'] == 'system' %}{{ message['content'] }}{% elif message['role'] == 'user' %}{{ message['content'] }}{% endif %}{% endfor %}"
      
      # Performance optimizations (adjusted for 2048 context window)
      pipeline_parallel_size: 1
      max_num_batched_tokens: 8192        # Reduced to fit multiple 2048-token sequences
      max_num_seqs: 64                    # Reduced to prevent memory issues
      
    # Request batching configuration
    enable_batching: true
    batch_size: 32
    batch_timeout: 1.0
  
  grader_shortname: "gpt-4.1"
  model_config_file: "model_servers.yaml"

rag:
  enabled: false  # Disable for pure generation testing
  use_context_field: false

processing:
  parallel_workers: 8
  question_format: "mc"
  verbose: true
  random_selection: null
  random_seed: 42
  
  # âœ¨ NEW: Comprehensive Checkpointing and Progress Monitoring
  enable_checkpointing: true              # Enable automatic checkpointing
  checkpoint_interval: 1024                 # Save checkpoint every 50 completed questions
  checkpoint_directory: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/norag/smol-3b/checkpoints"     # Directory for checkpoint files
  resume_from_checkpoint: null            # Specify checkpoint file to resume from (null = auto-detect)
  auto_resume: true                       # Automatically resume from latest checkpoint
  progress_bar: true                      # Show progress bar with percentage
  save_incremental: false                 # Ultra-safe mode: save after every question (slower)

output:
  save_incorrect: true
  output_directory: "/rbstor/ac.ogokdemir/ArgoniumRick/reasoning-evals/norag/smol-3b"
  output_prefix: "smol-3b_norag_checkpointed"

# ðŸ”‹ Production Safety Features:
# - Automatic checkpointing every 50 questions
# - Auto-resume from crashes/interruptions  
# - Progress monitoring with percentage completion
# - Memory-safe: doesn't store everything in RAM
# - Crash recovery: can resume from any checkpoint
# - Ultra-safe mode option for critical workloads 